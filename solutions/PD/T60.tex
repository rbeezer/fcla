%%%%(c)
%%%%(c)  This file is a portion of the source for the textbook
%%%%(c)
%%%%(c)    A First Course in Linear Algebra
%%%%(c)    Copyright 2004 by Robert A. Beezer
%%%%(c)
%%%%(c)  See the file COPYING.txt for copying conditions
%%%%(c)
%%%%(c)
Let $\set{\vect{u}_1,\,\vect{u}_2,\,\vect{u}_3}$ and $\set{\vect{v}_1,\,\vect{v}_2,\,\vect{v}_3}$ be bases for $U$ and $V$ (respectively).  Then, the set $\set{\vect{u}_1,\,\vect{u}_2,\,\vect{u}_3,\,\vect{v}_1,\,\vect{v}_2,\,\vect{v}_3}$ is linearly dependent, since \acronymref{theorem}{G} says we cannot have 6 linearly independent vectors in a vector space of dimension 5.  So we can assert that there is a non-trivial relation of linear dependence,
%
\begin{equation*}
a_1\vect{u}_1+a_2\vect{u}_2+a_3\vect{u}_3+b_1\vect{v}_1+b_2\vect{v}_2+b_3\vect{v}_3=\zerovector
\end{equation*}
%
where $a_1,\,a_2,\,a_3$ and $b_1,\,b_2,\,b_3$ are not all zero.\par
%
We can rearrange this equation as
%
\begin{equation*}
a_1\vect{u}_1+a_2\vect{u}_2+a_3\vect{u}_3=-b_1\vect{v}_1-b_2\vect{v}_2-b_3\vect{v}_3
\end{equation*}
%
This is an equality of two vectors, so we can give this common vector a name, say $\vect{w}$, 
%
\begin{equation*}
\vect{w}=a_1\vect{u}_1+a_2\vect{u}_2+a_3\vect{u}_3=-b_1\vect{v}_1-b_2\vect{v}_2-b_3\vect{v}_3
\end{equation*}
%
This is the desired non-zero vector, as we will now show.\par
%
First, since $\vect{w}=a_1\vect{u}_1+a_2\vect{u}_2+a_3\vect{u}_3$, we can see that $\vect{w}\in U$.  Similarly, $\vect{w}=-b_1\vect{v}_1-b_2\vect{v}_2-b_3\vect{v}_3$, so $\vect{w}\in V$.  This establishes that $\vect{w}\in U\cap V$ (\acronymref{definition}{SI}).\par
%
Is $\vect{w}\neq\zerovector$?  Suppose not, in other words, suppose $\vect{w}=\zerovector$.  Then 
%
\begin{equation*}
\zerovector=\vect{w}=a_1\vect{u}_1+a_2\vect{u}_2+a_3\vect{u}_3
\end{equation*}
%
Because $\set{\vect{u}_1,\,\vect{u}_2,\,\vect{u}_3}$ is a basis for $U$, it is a linearly independent set and the relation of linear dependence above means we must conclude that $a_1=a_2=a_3=0$.  By a similar process, we would conclude that $b_1=b_2=b_3=0$.  But this is a contradiction since $a_1,\,a_2,\,a_3,\,b_1,\,b_2,\,b_3$ were chosen so that some were nonzero.  So $\vect{w}\neq\zerovector$.\par
%
How does this generalize?  All we really needed was the original relation of linear dependence that resulted because we had ``too many'' vectors in $W$.  A more general statement would be: Suppose that $W$ is a vector space with dimension $n$, $U$ is a subspace of dimension $p$ and $V$ is a subspace of dimension $q$.  If $p+q>n$, then $U\cap V$ contains a non-zero vector.
