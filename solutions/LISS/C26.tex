%%%%(c)
%%%%(c)  This file is a portion of the source for the textbook
%%%%(c)
%%%%(c)    A First Course in Linear Algebra
%%%%(c)    Copyright 2004 by Robert A. Beezer
%%%%(c)
%%%%(c)  See the file COPYING.txt for copying conditions
%%%%(c)
%%%%(c)
\begin{enumerate}
\item
The matrices in $S$ will span $M_{2,2}$ if for any $\begin{bmatrix} x& y\\z& w\end{bmatrix}$, there are coefficients $a, b, c, d, e$ so that 
%
\begin{align*}
a\begin{bmatrix} 1 & 2\\ 2 & 1 \end{bmatrix} + 
b\begin{bmatrix} 2 & 1\\-1 & 2 \end{bmatrix} + 
c\begin{bmatrix} 0 & 1 \\ 1 & 2\end{bmatrix} + 
d\begin{bmatrix} 1 & 0 \\ 1 & 1\end{bmatrix} + 
e\begin{bmatrix} 1 & 4 \\ 0 & 3 \end{bmatrix} 
&= 
\begin{bmatrix} x & y \\ z & w \end{bmatrix}
\end{align*}
%
Thus, we have 
%
\begin{align*}
\begin{bmatrix} 
a + 2b + d + e & 2a + b + c + 4e\\ 
2a - b + c + d& a + 2b + 2c + d + 3e
\end{bmatrix} 
&=
\begin{bmatrix} 
x & y \\
 z & w 
\end{bmatrix}\\
\intertext{so we have  the matrix equation}\\
\begin{bmatrix} 
1 & 2 & 0 & 1 & 1 \\ 
2 & 1 & 1 & 0 & 4\\ 
2 & -1 & 1 & 1 & 0\\ 
1 & 2 & 2 & 1 & 3 
\end{bmatrix}
\colvector{a\\b\\c\\d\\e} 
&= 
\colvector{x\\y\\z\\w}
\end{align*}
%
This system will have a solution for {\em every} vector on the right side if the row-reduced coefficient matrix has a leading one in every row, since then it is never possible to have a leading 1 appear in the final column of a row-reduced augmented matrix.  
%
\begin{align*}
\begin{bmatrix} 
1 & 2 & 0 & 1 & 1 \\ 
2 & 1 & 1 & 0 & 4\\ 
2 & -1 & 1 & 1 & 0\\ 
1 & 2 & 2 & 1 & 3 
\end{bmatrix} 
\rref 
\begin{bmatrix}
\leading{1}& 0 & 0 &  0 & 1\\ 
0 & \leading{1} & 0 & 0 & 1\\ 
0 & 0 & \leading{1} & 0 & 1\\ 
0 &  0 & 0 & \leading{1} & -2
\end{bmatrix}
\end{align*}
%
Since there is a leading one in each row of the row-reduced coefficient matrix, there is a solution for every vector $\colvector{x\\y\\z\\w}$, which means that there is a solution to the original equation for every matrix $\begin{bmatrix} x & y\\ z & w \end{bmatrix}$.  Thus, the original four matrices span $M_{2,2}$.
%
\item The matrices in $S$ are linearly independent if the only solution to 
%
\begin{align*}
a\begin{bmatrix} 1 & 2\\ 2 & 1 \end{bmatrix} + 
b\begin{bmatrix} 2 & 1\\-1 & 2 \end{bmatrix} + 
c\begin{bmatrix} 0 & 1 \\ 1 & 2\end{bmatrix} + 
d\begin{bmatrix} 1 & 0 \\ 1 & 1 \end{bmatrix} + 
e\begin{bmatrix} 1 & 4 \\ 0 & 3 \end{bmatrix} 
&= 
\begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix}
\end{align*}
%
is $a = b = c = d = e = 0$.\par
%
We have 
%
\begin{align*}
\begin{bmatrix} 
a + 2b + d + e & 2a + b + c + 4e\\ 
2a - b + c + d & a + 2b + 2c + d + 3e
\end{bmatrix} 
&=  
\begin{bmatrix} 
1 & 2 & 0 & 1 & 1 \\ 
2 & 1 & 1 & 0 & 4\\ 
2 & -1 & 1 & 1 & 0\\ 
1 & 2 & 2 & 1 & 3 \end{bmatrix}
\colvector{a\\b\\c\\d\\e} 
= 
\begin{bmatrix} 
0 & 0 \\ 
0 & 0 \end{bmatrix}
\end{align*}
%
so we need to find the nullspace of the matrix
%
\begin{align*}
\begin{bmatrix} 
1 & 2 & 0 & 1 & 1 \\ 
2 & 1 & 1 & 0 & 4\\ 
2 & -1 & 1 & 1 & 0\\ 
1 & 2 & 2 & 1 & 3 
\end{bmatrix}
\end{align*}
%
We row-reduced this matrix in part (a), and found that there is a column without a leading 1, which correspons to a free variable in a description of the solution set to the homogeneous system, so the nullspace is nontrivial and there are an infinite number of solutions to 
%
\begin{align*}
a\begin{bmatrix} 1 & 2\\ 2 & 1 \end{bmatrix} + 
b\begin{bmatrix} 2 & 1\\-1 & 2 \end{bmatrix} + 
c \begin{bmatrix} 0 & 1 \\ 1 & 2\end{bmatrix} + 
d \begin{bmatrix} 1 & 0 \\ 1 & 1 \end{bmatrix} + 
e \begin{bmatrix} 1 & 4 \\ 0 & 3 \end{bmatrix} 
&= 
\begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix}
\end{align*}
%
Thus, this set of matrices is not linearly independent.
%
\end{enumerate}